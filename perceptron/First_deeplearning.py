# 폐암 수술 환자의 생존율 예측하기

# 앞서 배웠던 이론들을 토대로 이 코드를 섬세하고 면밀하게 다시 한번 분석해 본다.

#모듈 가져오기
from keras.models import Sequential
from keras.layers import Dense

import numpy
import tensorflow as tf

# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.
seed = 0
numpy.random.seed(seed)
tf.set_random_seed(seed)

# 준비된 수술 환자 데이터를 불러입니다.
Data_set = numpy.loadtxt("../dataset/ThoraricSurgery.csv",delimiter=",")

# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장합니다.
X = Data_set[:,0:17]
Y = Data_set[:,17]

######################################################################################################

# 입력층 은닉층 출력층에 관하여
# 앞서 살펴보았던 이론을 토대로 어느정도 해석이 가능해졌다.
# 먼저 keras 라이브러리를 이용해 Sequential()함수로 모델을 생성한다.
# 이 생성한 모델에 add 함수를 이용하면 층을 만들 수 있다.
# 층은 우리가 앞서 배웠던 다중 퍼셉트론 이론에서의 층을 의미한다.
# 여기서는 두개의 층을 생성하는데 마지막 층이 출력층이고 그 전 층이 은닉층이다.
# 생성한 모델에 add함수를 이용해 층을 생성하고, Dense함수를 이용하여 30개의 은닉층 노드를 생성한다.
# input_dim = 17 이란 입력으로 받을 데이터 17개를 의미한다. 
# activation='relu'는 짐작 가능하겠지만 활성화 함수로 relu를 사용하겠다는 의미다.
# 출력층에서는 1개의 출력 노드를 가지며, 활성화 함수로는 시그모이드 함수를 사용했다.


model = Sequential()
model.add(Dense(30, input_dim = 17, activation='relu'))
model.add(Dense(1,activation='sigmoid'))

######################################################################################################


# 모델의 컴파일
# 앞서 지정한 모델이 효과적으로 구현될 수 있게 여러가지 환경 설정을 해주면서 컴파일 하는 부분이다.

model.compile(loss='mean_squared_logarithmic_error',optimizer='adam',metrics=['accuracy'])
# 지난번 의문들
# loss, optimizer의 의미에 대하여
# loss : 한번 실행될때마다 오차 값을 추적하는 함수
# optimizer : 오차를 어떻게 줄여 나갈지 정하는 함수 입니다.
# 라고 적어놨는데 이때는 아무것도 몰랐지만 이제는 대충 분석이 가능하다.

# 먼저 loss = 'mean_squared_error는 우리가 앞서 배웠던 평균 제곱 오차 함수이다.
# 경우에 따라서는 이 함수를 바꾸면 조금 더 좋은 효과를 나타내기도 한다. EX) 교차 엔트로피
# optimizer는 최적화 함수로써 고급 경사 하강법의 한 종류인 adam을 사용한 것을 볼 수 있다.
# 메트릭스는 평가 기준을 정의한다. 여기서는 정확도(accuracy)로 하였다.

################################################################################################################

# 모델 정의하기
# 컴파일 단계에서 정해진 환경을 주어진 데이터를 불러 실행시킬 때 사용되는 함수가 fit 함수이다.
# epochs(에포크)는 학습프로세스가 모든 샘플에 대해 한번 실행되는 것을 1 에포크라고 한다.
# 에포크 1000은 각 샘플이 ㅓ음부터 끝까지 1000번 재사용될때까지 실행을 반복하라는 뜻이다.
# batch_size는 샘플을 한번에 몇개씩 처리할지에 대한 부분이다. 10은 전체 470개의 샘플을 10개씩 끊어서 집어넣으라는 의미이다.
# batch_size가 너무 크면 학습속도가 느려지고 너무 작으면 각 실행값의 편차가 생겨서 전체 결과값이 불안정해질 수 있다.

model.fit(X,Y,epochs=30,batch_size=10)

################################################################################################################


# 출력 하는 부분

loss = (model.evaluate(X,Y)[0])
score = (model.evaluate(X,Y)[1])

print("\n Loss : %.4f" % loss)

print("\n Accuracy : %.4f" % score)


################################################################################################################

